import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'DeJavu Serif'
plt.rcParams['font.serif'] = ['Times New Roman']
import calendar
import pandas as pd
from functions import *
import statistics as st
from statsmodels.distributions.empirical_distribution import ECDF
from scipy import stats


file_path=r'C:\\Users\\lehri\\Documents\\GitHub\\dust_solar_power\\'


%store -r tceq_pm10_export
%store -r tceq_pm25_export
%store -r tceq_pm10_monthly_all
%store -r tceq_pm25_monthly_all
%store -r wind_df_2019
%store -r wind_df_2020
%store -r wind_df_2021

wind_years=[wind_df_2019,wind_df_2020,wind_df_2021]



%store -r ellipse_inv_hourly
%store -r ellipse_trad_hourly


ellipse_inv_hourly_totals=[]
ellipse_inv_hourly_totals=np.append(ellipse_inv_hourly_totals,ellipse_inv_hourly[0])
ellipse_inv_hourly_totals=np.append(ellipse_inv_hourly_totals,ellipse_inv_hourly[1])
ellipse_inv_hourly_totals=np.append(ellipse_inv_hourly_totals,ellipse_inv_hourly[2])

ellipse_trad_hourly_totals=[]
ellipse_trad_hourly_totals=np.append(ellipse_trad_hourly_totals,ellipse_trad_hourly[0])
ellipse_trad_hourly_totals=np.append(ellipse_trad_hourly_totals,ellipse_trad_hourly[1])
ellipse_trad_hourly_totals=np.append(ellipse_trad_hourly_totals,ellipse_trad_hourly[2])


'''
Seasonality of Data, following ranges were used:
spring (March–May), summer (June–August), fall (September–November) and winter (December–February)
'''


wind_all=np.append(wind_df_2019.values,wind_df_2020.values)
wind_all=np.append(wind_all,wind_df_2021.values)


#we want to compare the hourly pm data with the hourly wind data
tceq_pm10_all=np.hstack(tceq_pm10_export)
tceq_pm25_all=np.hstack(tceq_pm25_export)
#the nans are already removed, but in case that changes use below
#tceq_pm10_all=tceq_pm10_all[~np.isnan(tceq_pm10_all)]
#tceq_pm25_all=tceq_pm25_all[~np.isnan(tceq_pm25_all)]
#Make sure negative values are removed
tceq_pm10_all=tceq_pm10_all[tceq_pm10_all>0]
tceq_pm25_all=tceq_pm25_all[tceq_pm25_all>0]


tceq_pm10_all.size


fig,ax=plt.subplots(figsize=(6,6))
pm10_log_transform=np.log10(tceq_pm10_all)
pm25_log_transform=np.log10(tceq_pm25_all)
ax.set_ylabel('Number of Observations')
ax.set_xlabel('log10(Count)')
ax.hist(pm10_log_transform, bins=50, label='PM10',color='tomato', alpha=0.7)
ax.hist(pm25_log_transform, bins=50, label='PM2.5', alpha=0.7)
ax.legend()
ax.grid()


#ECDFs for entirety of study period
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
tceq_cams49_pm10_norm = normalize(tceq_pm10_all)
tceq_cams49_pm25_norm = normalize(tceq_pm25_all)

wind_all_norm=normalize(wind_all)
ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3= ECDF(wind_all_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='Wind Speed')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')


#ECDFs per year
fig,ax=plt.subplots(nrows=1, ncols=3, sharex=True, sharey=True, figsize=(12,6))
#plot_dict={0:'r',1:'g',2:'b'}
for i in [0,1,2]:
    #normalize all data
    '''TEST'''
    tceq_pm10=np.array(tceq_pm10_export[i])
    tceq_pm25=np.array(tceq_pm25_export[i])
    dust_trad_norm=normalize(ellipse_trad_hourly[i][ellipse_trad_hourly[i]>300])
    dust_inv_norm=normalize(ellipse_inv_hourly[i][ellipse_inv_hourly[i]>300])
    tceq_cams49_pm10_norm = normalize(tceq_pm10[tceq_pm10>400])
    tceq_cams49_pm25_norm = normalize(tceq_pm25[tceq_pm25>60])

    #dust_norm=normalize(ellipse_inv_hourly[i])
    #tceq_cams49_pm10_norm = normalize(tceq_pm10_export[i])
    #tceq_cams49_pm25_norm = normalize(tceq_pm25_export[i])
    #wind_norm=normalize(wind_years[i].values)
    
    ecdf1 = ECDF(tceq_cams49_pm10_norm)
    ecdf2 = ECDF(tceq_cams49_pm25_norm)
    '''Test'''   
    ecdf3= ECDF(dust_trad_norm)
    ecdf4= ECDF(dust_inv_norm)
    #ecdf3= ECDF(wind_norm)
    #ecdf4= ECDF(dust_norm)
    ax[i].step(ecdf1.x, ecdf1.y, where='post',label=f'PM10 {i+2019}',color='tomato')
    ax[i].step(ecdf2.x, ecdf2.y, where='post', label=f'PM2.5 {i+2019}',color='b')
    ax[i].step(ecdf3.x, ecdf3.y, where='post', label=f'Wind Speed {i+2019}', linestyle='dashed')
    ax[i].step(ecdf4.x, ecdf4.y, where='post', label=f'dust_score {i+2019}', linestyle='dashdot')


    print("Stats for alld data in Year ",i+2019)
    '''
    print("ED PM10 - PM2.5 ", stats.energy_distance(tceq_cams49_pm10_norm,tceq_cams49_pm25_norm))
    print("ED PM10 - Wind Spd ", stats.energy_distance(tceq_cams49_pm10_norm,wind_norm))
    print("ED PM25 - Wind Spd ", stats.energy_distance(tceq_cams49_pm25_norm,wind_norm))
    print("ED PM10 - dust_score ", stats.energy_distance(tceq_cams49_pm10_norm,dust_norm))
    print("ED PM25 - dust_score ", stats.energy_distance(tceq_cams49_pm25_norm,dust_norm))
    print("ED Wind Spd - dust_score ", stats.energy_distance(wind_norm, dust_norm))
    '''
    x=normalize(np.linspace(0,100,1000))
    ecdf_normdist = ECDF(x)
    ax[i].step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')
    ax[i].legend(loc='lower right')
    ax[i].grid()

fig.text(0.5, 0, 'Cumulative Probability', ha='center')
fig.text(0, 0.5, 'Normalized Observations', va='center', rotation='vertical')
fig.tight_layout(pad=1)
#fig.supxlabel('common_x')
#fig.supylabel('common_y')


#ECDFs per month
#data seems to lose some of its granularity, i.e. ecdf starts to resemble a normal distribution
#which may imply that the data is almost random
fig,ax=plt.subplots(figsize=(6,6))

plot_dict={0:'r',1:'g',2:'b'}
for i in [0,1,2]:
    wind_monthly_means=[]
    for month in range(1,13):
        wind_monthly_means.append(wind_years[i][wind_years[i].index.month==month].mean())

    tceq_cams49_pm10_norm = normalize(tceq_pm10_monthly_all[i])
    tceq_cams49_pm25_norm = normalize(tceq_pm25_monthly_all[i])
    wind_norm=normalize(wind_monthly_means)
    
    ecdf1 = ECDF(tceq_cams49_pm10_norm)
    ecdf2 = ECDF(tceq_cams49_pm25_norm)
    ecdf3= ECDF(wind_norm)
    
    ax.step(ecdf1.x, ecdf1.y, where='post',label=f'PM10 {i+2019}',color=plot_dict[i])
    ax.step(ecdf2.x, ecdf2.y, where='post', label=f'PM2.5 {i+2019}',color=plot_dict[i],linestyle='dotted')
    ax.step(ecdf3.x, ecdf3.y, where='post', label=f'Wind Speed {i+2019}', color=plot_dict[i], linestyle='dashed')

    
    ax.set_ylabel("Cumulative Probability")
    ax.set_xlabel("Normalized Observations")
    print("Stats for months in Year ",i+2019)
    print("ED PM10 - PM2.5 ", stats.energy_distance(tceq_cams49_pm10_norm,tceq_cams49_pm25_norm))
    print("ED PM10 - Wind Spd ", stats.energy_distance(tceq_cams49_pm10_norm,wind_norm))
    print("ED PM25 - Wind Spd ", stats.energy_distance(tceq_cams49_pm25_norm,wind_norm))

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')
ax.legend(loc='lower right')



fig,ax=plt.subplots(figsize=(6,6))
ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')
plot_dict={2019:'r',2020:'g',2021:'b'}
for year in [2019,2020,2021]:
    wind_spring=wind_years[year-2019][pd.date_range(start=f'{year}-03-01',end=f'{year}-05-31')].mean()
    wind_summer=wind_years[year-2019][pd.date_range(start=f'{year}-06-01',end=f'{year}-08-31')].mean()
    wind_fall=wind_years[year-2019][pd.date_range(start=f'{year}-09-01',end=f'{year}-11-30')].mean()

    pm10_spring=tceq_pm10_monthly_all[year-2019][2:5].mean()
    pm10_summer=tceq_pm10_monthly_all[year-2019][5:8].mean()
    pm10_autumn=tceq_pm10_monthly_all[year-2019][8:11].mean()
    pm25_spring=tceq_pm25_monthly_all[year-2019][2:5].mean()
    pm25_summer=tceq_pm25_monthly_all[year-2019][5:8].mean()
    pm25_autumn=tceq_pm25_monthly_all[year-2019][8:11].mean()    
    if year!=2021:        
        wind_winter=wind_years[year-2019][pd.date_range(start=f'{year}-12-01',end=f'{year}-12-31')]
        wind_winter=np.append(wind_winter,wind_years[year+1-2019][pd.date_range(start=f'{year+1}-01-01',end=f'{year+1}-02-28')]).mean()
        pm10_winter=np.append(tceq_pm10_monthly_all[year-2019][11],tceq_pm10_monthly_all[year+1-2019][0:2].tolist()).mean()
        pm25_winter=np.append(tceq_pm25_monthly_all[year-2019][11],tceq_pm25_monthly_all[year+1-2019][0:2].tolist()).mean()

    wind_season_year=np.array([wind_spring,wind_summer,wind_fall,wind_winter])
    pm10_season_year=np.array([pm10_spring,pm10_summer,pm10_autumn,pm10_winter])
    pm25_season_year=np.array([pm25_spring,pm25_summer,pm25_autumn,pm25_winter])
    wind_season_year_norm=normalize(wind_season_year)
    pm10_season_year_norm=normalize(pm10_season_year)
    pm25_season_year_norm=normalize(pm25_season_year)
    
    ecdf1 = ECDF(pm10_season_year_norm)
    ecdf2 = ECDF(pm25_season_year_norm)
    ecdf3= ECDF(wind_season_year_norm)
    
    ax.step(ecdf1.x, ecdf1.y, where='post',label=f'PM10 {year}',color=plot_dict[year])
    ax.step(ecdf2.x, ecdf2.y, where='post', label=f'PM2.5 {year}',color=plot_dict[year],linestyle='dotted')
    ax.step(ecdf3.x, ecdf3.y, where='post', label=f'Wind Speed {year}', color=plot_dict[year], linestyle='dashed')
    

    print("Stats for Seasons in Year ",year)
    print("ED PM10 - PM2.5 ", stats.energy_distance(pm10_season_year_norm,pm25_season_year_norm))
    print("ED PM10 - Wind Spd ", stats.energy_distance(pm10_season_year_norm,wind_season_year_norm))
    print("ED PM25 - Wind Spd ", stats.energy_distance(pm25_season_year_norm,wind_season_year_norm))
x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')    
ax.legend(loc='lower right')


fig,ax=plt.subplots(2,1,figsize=(12,6))
ax[0].set_ylabel('PM Concentration [$μg/m^2$]')
ax[0].set_xlabel("Seasons")
ax2=ax[0].twinx()
ax[1].set_ylabel("Wind Speed [$m/s$]")
ax[0].set_xticks(np.arange(4),["Spring","Summer","Autumn","Winter"], rotation=330 )
ax[1].set_xticks(np.arange(4),["Spring","Summer","Autumn","Winter"], rotation=330 )

plot_dict={2019:'r',2020:'g',2021:'b'}
for year in [2019,2020,2021]:
    wind_spring=wind_years[year-2019][pd.date_range(start=f'{year}-03-01',end=f'{year}-05-31')].mean()
    wind_summer=wind_years[year-2019][pd.date_range(start=f'{year}-06-01',end=f'{year}-08-31')].mean()
    wind_fall=wind_years[year-2019][pd.date_range(start=f'{year}-09-01',end=f'{year}-11-30')].mean()

    pm10_spring=tceq_pm10_monthly_all[year-2019][2:5].mean()
    pm10_summer=tceq_pm10_monthly_all[year-2019][5:8].mean()
    pm10_autumn=tceq_pm10_monthly_all[year-2019][8:11].mean()
    pm25_spring=tceq_pm25_monthly_all[year-2019][2:5].mean()
    pm25_summer=tceq_pm25_monthly_all[year-2019][5:8].mean()
    pm25_autumn=tceq_pm25_monthly_all[year-2019][8:11].mean()    
    if year!=2021:        
        wind_winter=wind_years[year-2019][pd.date_range(start=f'{year}-12-01',end=f'{year}-12-31')]
        wind_winter=np.append(wind_winter,wind_years[year+1-2019][pd.date_range(start=f'{year+1}-01-01',end=f'{year+1}-02-28')]).mean()
        pm10_winter=np.append(tceq_pm10_monthly_all[year-2019][11],tceq_pm10_monthly_all[year+1-2019][0:2].tolist()).mean()
        pm25_winter=np.append(tceq_pm25_monthly_all[year-2019][11],tceq_pm25_monthly_all[year+1-2019][0:2].tolist()).mean()

    wind_season_year=np.array([wind_spring,wind_summer,wind_fall,wind_winter])
    pm10_season_year=np.array([pm10_spring,pm10_summer,pm10_autumn,pm10_winter])
    pm25_season_year=np.array([pm25_spring,pm25_summer,pm25_autumn,pm25_winter])
    ax[0].plot(pm10_season_year, label=f"Seasonal PM10 {year}", color=plot_dict[year])
    ax[0].plot(pm25_season_year, label=f"Seasonal PM2.5 {year}", color=plot_dict[year], linestyle='dotted')
    ax[1].plot(wind_season_year, label=f"Seasonal Wind {year}")
    
fig.legend()


#ECDFs PM non normalized
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
tceq_cams49_pm10_norm = tceq_pm10_all
tceq_cams49_pm25_norm = tceq_pm25_all

ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf_pm10x=ecdf1.x
ecdf_pm10y=ecdf1.y

ecdf_pm25x=ecdf2.x
ecdf_pm25y=ecdf2.y
ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')

x=np.linspace(min(tceq_cams49_pm10_norm),max(tceq_cams49_pm10_norm),1000)
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution',color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Observations")
ax.legend(loc='lower right')
ax.grid()


tceq_pm25_all.max()


print(ecdf_pm10x[np.where(ecdf_pm10y>0.90,ecdf_pm10y,0)>0])
print(ecdf_pm25x[np.where(ecdf_pm25y>0.90,ecdf_pm25y,0)>0])
ecdf_pm25x[ecdf_pm25y>0.99]
ecdf_pm10x[ecdf_pm10y>0.99]


def get_iqr(array):
    q75, q25 = np.percentile(array, [75 ,25])
    return q75 - q25
def get_percentiles(array):
    '''
    Returns the 10th, 50th and 90th percentiles
    '''
    return [np.percentile(array,10),np.percentile(array,50),np.percentile(array,90)]


pm25_threshold=np.percentile(tceq_pm25_all,99)
pm25_percentiles=get_percentiles(tceq_pm25_all)
pm10_percentiles=get_percentiles(tceq_pm10_all)
pm10_percentiles
#pm10_threshold=np.percentile(tceq_pm10_all,99)
#dust_inv_threshold=np.percentile(ellipse_inv_hourly_totals,80)
#dust_trad_threshold=np.percentile(ellipse_trad_hourly_totals,80)





#ECDFs for entirety of study period
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
dust_norm=normalize(ellipse_inv_hourly_totals)
tceq_cams49_pm10_norm = normalize(tceq_pm10_all)
tceq_cams49_pm25_norm = normalize(tceq_pm25_all)

wind_all_norm=normalize(wind_all)
ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3= ECDF(wind_all_norm)
ecdf4=ECDF(dust_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='Wind Speed')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')

print(stats.energy_distance(tceq_cams49_pm10_norm,dust_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_norm))
print(stats.energy_distance(wind_norm,dust_norm))



#ECDFs INVERTED and TRADITIONAL WIND DUSTSCORE SAMPLING METHODS for entirety of study period
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
dust_trad_norm=normalize(ellipse_trad_hourly_totals)
dust_inv_norm=normalize(ellipse_inv_hourly_totals)
tceq_cams49_pm10_norm = normalize(tceq_pm10_all)
tceq_cams49_pm25_norm = normalize(tceq_pm25_all)

ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3=ECDF(dust_trad_norm)
ecdf4=ECDF(dust_inv_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='dust_score Trad')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score Inv')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')

print(stats.energy_distance(tceq_cams49_pm10_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm10_norm,dust_trad_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_trad_norm))
print(stats.energy_distance(x,dust_trad_norm))
print(stats.energy_distance(x,dust_inv_norm))



#ECDFs INVERTED and TRADITIONAL WIND DUSTSCORE SAMPLING METHODS for entirety of study period
#FOR DUST_SCORE AND PM THRESHOLD VALUES!
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
dust_trad_norm=normalize(ellipse_trad_hourly_totals[ellipse_trad_hourly_totals>dust_trad_threshold])
dust_inv_norm=normalize(ellipse_inv_hourly_totals[ellipse_inv_hourly_totals>dust_inv_threshold])
tceq_cams49_pm10_norm = normalize(tceq_pm10_all[tceq_pm10_all>pm10_threshold])
tceq_cams49_pm25_norm = normalize(tceq_pm25_all[tceq_pm25_all>pm25_threshold])

ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3=ECDF(dust_trad_norm)
ecdf4=ECDF(dust_inv_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='dust_score Trad')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score Inv')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')
ax.grid()
print(stats.energy_distance(tceq_cams49_pm10_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm10_norm,dust_trad_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_trad_norm))
print(stats.energy_distance(x,dust_trad_norm))
print(stats.energy_distance(x,dust_inv_norm))



#ECDFs INVERTED and TRADITIONAL WIND DUSTSCORE SAMPLING METHODS for entirety of study period
#FOR dust_score<380 ONLY! and also BELOW PM thresholds
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
dust_trad_norm=normalize(ellipse_trad_hourly_totals[ellipse_trad_hourly_totals<300])
dust_inv_norm=normalize(ellipse_inv_hourly_totals[ellipse_inv_hourly_totals<300])
tceq_cams49_pm10_norm = normalize(tceq_pm10_all[tceq_pm10_all<400])
tceq_cams49_pm25_norm = normalize(tceq_pm25_all[tceq_pm25_all<60])

ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3=ECDF(dust_trad_norm)
ecdf4=ECDF(dust_inv_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='dust_score Trad')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score Inv')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')

print(stats.energy_distance(tceq_cams49_pm10_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm10_norm,dust_trad_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_trad_norm))
print(stats.energy_distance(x,dust_trad_norm))
print(stats.energy_distance(x,dust_inv_norm))



#ECDFs INVERTED and TRADITIONAL WIND DUSTSCORE SAMPLING METHODS for entirety of study period
#FOR dust_score>380 ONLY! and also PM thresholds like before
fig,ax=plt.subplots(figsize=(6,6))
#normalize all data
dust_trad_norm=normalize(ellipse_trad_hourly_totals[ellipse_trad_hourly_totals>380])
dust_inv_norm=normalize(ellipse_inv_hourly_totals[ellipse_inv_hourly_totals>380])
tceq_cams49_pm10_norm = normalize(tceq_pm10_all[tceq_pm10_all>400])
tceq_cams49_pm25_norm = normalize(tceq_pm25_all[tceq_pm25_all>60])

ecdf1 = ECDF(tceq_cams49_pm10_norm)
ecdf2 = ECDF(tceq_cams49_pm25_norm)
ecdf3=ECDF(dust_trad_norm)
ecdf4=ECDF(dust_inv_norm)

ax.step(ecdf1.x, ecdf1.y, where='post',label='PM10')
ax.step(ecdf2.x, ecdf2.y, where='post', label='PM2.5')
ax.step(ecdf3.x, ecdf3.y, where='post', label='dust_score Trad')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score Inv')

x=normalize(np.linspace(0,100,1000))
ecdf_normdist = ECDF(x)
ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("Normalized Observations")
ax.legend(loc='lower right')

print(stats.energy_distance(tceq_cams49_pm10_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_inv_norm))
print(stats.energy_distance(tceq_cams49_pm10_norm,dust_trad_norm))
print(stats.energy_distance(tceq_cams49_pm25_norm,dust_trad_norm))
print(stats.energy_distance(x,dust_trad_norm))
print(stats.energy_distance(x,dust_inv_norm))



#ECDFs OF NOT NORMALIZED TRAD AND INV WIND DUST_SCORE
fig,ax=plt.subplots(figsize=(12,6))
#normalize all data
dust_trad_norm=ellipse_trad_hourly_totals
dust_inv_norm=ellipse_inv_hourly_totals
dust_trad_norm_300=ellipse_trad_hourly_totals[ellipse_trad_hourly_totals>380]
dust_inv_norm_300=ellipse_inv_hourly_totals[ellipse_inv_hourly_totals>380]
dust_trad_norm_100=ellipse_trad_hourly_totals[ellipse_trad_hourly_totals>300]
dust_inv_norm_100=ellipse_inv_hourly_totals[ellipse_inv_hourly_totals>300]
ecdf1=ECDF(dust_trad_norm_300)
ecdf2=ECDF(dust_inv_norm_300)
ecdf3=ECDF(dust_trad_norm)
ecdf4=ECDF(dust_inv_norm)
ecdf5=ECDF(dust_trad_norm_100)
ecdf6=ECDF(dust_inv_norm_100)

ax.step(ecdf1.x, ecdf1.y, where='post', label='dust_score Trad >380')
ax.step(ecdf2.x, ecdf2.y, where='post', label='dust_score Inv >380')
ax.step(ecdf3.x, ecdf3.y, where='post', label='dust_score Trad')
ax.step(ecdf4.x, ecdf4.y, where='post', label='dust_score Inv')
ax.step(ecdf5.x, ecdf5.y, where='post', label='dust_score Trad>300')
ax.step(ecdf6.x, ecdf6.y, where='post', label='dust_score Inv>300')
#x=np.linspace(0,100,len(dust_trad_norm))
#ecdf_normdist = ECDF(x)
#ax.step(ecdf_normdist.x, ecdf_normdist.y, where='post', label='Normal Distribution', color='black')

ax.set_ylabel("Cumulative Probability")
ax.set_xlabel("dust_score Observations")
ax.legend(loc='lower right')

print(stats.energy_distance(x,dust_trad_norm))
print(stats.energy_distance(x,dust_inv_norm))



plt.bar(ellipse_trad_hourly[0])


##to do#
'''
heatmap of EDs of ECDFs windspd,pm10,pm25,dust_score for the following time ranges:
'entire study period
'per year'
'per month? 
'per season?
    per month and per season do not have a very interesting ECDF, too few datapoints, maybe the problem is just using the mean?
    but also in the end there is too much info to display, so maybe stick to entire study period and year and continue with below:

the distribution/barcharts per month and season could be plotted separately to show the trends in the data

also comparing EDs of Inverted and traditional wind for ellipse sampling method dust_scores with pm10 and pm2.5,
Inverted is obviosly more powerful, plus fewer Nans, but is ED between these two different methods enough?

=understand why the ECDFs look different when we only use dustscore above a certain number? Basically should we do that or not?

# /if my data fits a normal distribution does it mean it could just be rando?


Interpretation for dust_inv_norm in all period ECDFS

we have 3 clusters of where our main data is, and jumps in between (the flat line )
we lack intermediate data, which would help to smoothen the curve

Does the method with traditional wind have better perfomance with higher dust_score values?
when using a threshold for PM10 and PM2.5 with 400 and 60 resp (taken from the 2019/04/10 dust event)
with a dust_scorethreshold of 300 we get the best ED results for PM and dust_score
does it make sense to fine-tune the threshold?
another question is why do the ecdfs (starting at 0) flatline so 'early' comapred to the >300 ones?)

Basically look at the Trad wind method at >300, it is a very smooth curve compared to all others.

my interpretation so far, the sampling method using trad wind direction has hit a sweet spot for finding 
high dust_scores. Because when we compare the ECDFs of PMs with the dust_score sampling method (both methods) we 
find no similarities in the distribution. So basically when it comes to looking for similarities between very high
PM values and very high dust_score values, we have a jackpot. But strangely, not with the method we expected.
The method using traditional wind direction is basically sampling dust_scores in the direction of the wind. But
shouldn't we be looking in the other direction? E.g. the way the wind has blown the dust? 
Perhaps something else is happening here I didn't think about.
Maybe the trad wind direction helps pick out those particles that are still upwind from CAMS49

Anyways, thank Goodness I decided to re-add the sampling method with trad wind back!
I think in general we can say this
the dust_score is not good at correlating smaller pm values!

'''

