{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17466627-ad40-4df0-be88-61f8e70d3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from pyhdf.SD import SD\n",
    "import pandas as pd\n",
    "from datetime import datetime, time, timedelta\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy.stats import pearsonr, mode\n",
    "import geopy\n",
    "from matplotlib.patches import Ellipse\n",
    "from functions import *\n",
    "# Path and Variable declarations\n",
    "# External harddrive path\n",
    "file_ext= \"D:\\\\NASA_AIRS\"\n",
    "file_path_plots=r\"C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\Plots\"\n",
    "# Internal testing folder\n",
    "file_wind_2019=r\"C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\NREL_NSRDB\\GHI_CAMS49_2019.csv\"\n",
    "file_wind_2020=r\"C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\NREL_NSRDB\\GHI_CAMS49_2020.csv\"\n",
    "file_wind_2021=r\"C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\NREL_NSRDB\\GHI_CAMS49_2021.csv\"\n",
    "\n",
    "#sort file list\n",
    "folder_year_list=sorted(os.listdir(file_ext))\n",
    "\n",
    "# Coordinates for TECQ stations\n",
    "CAMS49 = [31.6676,-106.288]\n",
    "CAMS1028 = [33.5856, -101.78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f19915d9-2f9d-4b85-babe-9f0c437fb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_spd_dir_2019=pd.read_csv(file_wind_2019, header=[2], engine=\"python\")\n",
    "wind_spd_dir_2020=pd.read_csv(file_wind_2020, header=[2], engine=\"python\")\n",
    "wind_spd_dir_2021=pd.read_csv(file_wind_2021, header=[2], engine=\"python\")\n",
    "\n",
    "wind_spd_dir = pd.concat([wind_spd_dir_2019, wind_spd_dir_2020, wind_spd_dir_2021], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3f8eaae-8e7e-47e1-af44-aac1d01b783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_spd_dir['Datetime']= pd.to_datetime(wind_spd_dir['Year'].astype(str) + '-' + wind_spd_dir['Month'].astype(str) + '-' + wind_spd_dir['Day'].astype(str) + '-' + wind_spd_dir['Hour'].astype(str), format='%Y-%m-%d-%H')\n",
    "#datetime.strptime(datetimeobj,'%Y-%m-%d')\n",
    "wind_spd_dir['Wind Speed']=wind_spd_dir['Wind Speed']*2.236936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07a8b820-36ab-4057-8366-c20f9e2bedd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Cloud Type</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>GHI</th>\n",
       "      <th>Solar Zenith Angle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.355404</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.908017</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.908017</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.131710</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.579098</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.565855</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.013242</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.460630</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.460630</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:00:00</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.236936</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year  Month  Day  Hour  Minute  Cloud Type  Wind Speed  \\\n",
       "Datetime                                                                      \n",
       "2019-01-01 00:00:00  2019      1    1     0       0           0    3.355404   \n",
       "2019-01-01 01:00:00  2019      1    1     1       0           0    2.908017   \n",
       "2019-01-01 02:00:00  2019      1    1     2       0           0    2.908017   \n",
       "2019-01-01 03:00:00  2019      1    1     3       0           0    3.131710   \n",
       "2019-01-01 04:00:00  2019      1    1     4       0           0    3.579098   \n",
       "...                   ...    ...  ...   ...     ...         ...         ...   \n",
       "2021-12-31 19:00:00  2021     12   31    19       0           0    1.565855   \n",
       "2021-12-31 20:00:00  2021     12   31    20       0           0    2.013242   \n",
       "2021-12-31 21:00:00  2021     12   31    21       0           1    2.460630   \n",
       "2021-12-31 22:00:00  2021     12   31    22       0           0    2.460630   \n",
       "2021-12-31 23:00:00  2021     12   31    23       0           0    2.236936   \n",
       "\n",
       "                     Wind Direction  DHI  DNI  GHI  Solar Zenith Angle  \n",
       "Datetime                                                                \n",
       "2019-01-01 00:00:00             118    0    0    0              171.15  \n",
       "2019-01-01 01:00:00             102    0    0    0              165.68  \n",
       "2019-01-01 02:00:00              92    0    0    0              153.87  \n",
       "2019-01-01 03:00:00              99    0    0    0              141.21  \n",
       "2019-01-01 04:00:00             108    0    0    0              128.46  \n",
       "...                             ...  ...  ...  ...                 ...  \n",
       "2021-12-31 19:00:00             290    0    0    0              112.28  \n",
       "2021-12-31 20:00:00             258    0    0    0              124.81  \n",
       "2021-12-31 21:00:00             243    0    0    0              137.54  \n",
       "2021-12-31 22:00:00             231    0    0    0              150.25  \n",
       "2021-12-31 23:00:00             215    0    0    0              162.48  \n",
       "\n",
       "[26304 rows x 12 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_spd_dir.set_index('Datetime', inplace=True)\n",
    "wind_spd_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d85f43b-cb6d-47e8-bc42-34e9ac774bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_float(data, num_bins):\n",
    "    # Create histogram bins\n",
    "    bins = np.linspace(np.min(data), np.max(data), num_bins)\n",
    "    # Digitize the data into bins\n",
    "    bin_indices = np.digitize(data, bins)\n",
    "    # Find mode bin index\n",
    "    mode_bin_index = mode(bin_indices).mode\n",
    "    print(bin_indices)\n",
    "    mode_value=data[mode_bin_index]\n",
    "    # Calculate the mode value within the mode bin\n",
    "    #mode_value = (bins[mode_bin_index] + bins[mode_bin_index + 1]) / 2\n",
    "    \n",
    "    # Count occurrences in the mode bin\n",
    "    mode_frequency = np.sum(bin_indices == mode_bin_index)\n",
    "\n",
    "    return mode_value, mode_frequency\n",
    "\n",
    "def points_inside_ellipse(center_cams, center_windv, semi_major_axis, points):\n",
    "    \"\"\"Find points inside the given ellipse.\n",
    "    center_cams is constant and based on which CAMS TCEQ ground station we want to use as a reference point\n",
    "    center_windv is based on wind speed and direction and can take a position in a circle around center_cams\n",
    "    while its distance depends on how far wind has carried dust in an hour\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    inside_points_dist = np.array([(distance(center_cams, point) + distance(center_windv, point)) for point in points])\n",
    "    inside_points = points[inside_points_dist <= 2 * semi_major_axis]\n",
    "    #inside_points = points[inside_points_dist <= semi_major_axis]\n",
    "    '''\n",
    "    for point in points:\n",
    "        # Calculate the distance from each point to the two foci of the ellipse\n",
    "        distance_to_foci = distance(center_cams, point) + distance(center_windv, point)\n",
    "        # Check if the sum of distances is less than or equal to the major axis\n",
    "        if distance_to_foci <= 2 * semi_major_axis:\n",
    "            inside_points.append(point)\n",
    "    '''\n",
    "    return inside_points\n",
    "\n",
    "\n",
    "def points_between_ellipses(first_focus, second_focus, first_focus_next, second_focus_next, semi_major_axis, semi_major_axis_next, points):\n",
    "    inner_points = points_inside_ellipse(first_focus, second_focus, semi_major_axis, points)\n",
    "    outer_points = points_inside_ellipse(first_focus_next, second_focus_next, semi_major_axis_next, points)\n",
    "    between_points = np.array([point for point in outer_points if point not in inner_points])\n",
    "\n",
    "    return between_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb3c2b8-0bcf-4603-b207-b203592efc25",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening folder: D:\\NASA_AIRS\\2019\n",
      "Opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.082.L1B.AIRS_Rad.v5.0.23.0.G19001113504.hdf\n",
      "Next file:  D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.098.L1B.AIRS_Rad.v5.0.23.0.G19001113440.hdf\n",
      "(135, 90)\n",
      "UTC:  2019-01-01 08:00:00\n",
      "MST:  2019-01-01 01:00:00\n",
      "CST:  2019-01-01 02:00:00\n",
      "Time of satellite data capture:  2019-01-01 01:00:00\n",
      "Error opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.082.L1B.AIRS_Rad.v5.0.23.0.G19001113504.hdf\n",
      "name 'wind_spd_dir' is not defined\n",
      "\n",
      "\n",
      "HDF file execution time: 3.0201869010925293 sec\n",
      "\n",
      "\n",
      "Opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.098.L1B.AIRS_Rad.v5.0.23.0.G19001113440.hdf\n",
      "Next file:  D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.192.L1B.AIRS_Rad.v5.0.23.0.G19002100753.hdf\n",
      "(135, 90)\n",
      "UTC:  2019-01-01 10:00:00\n",
      "MST:  2019-01-01 03:00:00\n",
      "CST:  2019-01-01 04:00:00\n",
      "Time of satellite data capture:  2019-01-01 03:00:00\n",
      "Error opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.098.L1B.AIRS_Rad.v5.0.23.0.G19001113440.hdf\n",
      "name 'wind_spd_dir' is not defined\n",
      "\n",
      "\n",
      "HDF file execution time: 0.4390990734100342 sec\n",
      "\n",
      "\n",
      "Opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.192.L1B.AIRS_Rad.v5.0.23.0.G19002100753.hdf\n",
      "Next file:  D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.208.L1B.AIRS_Rad.v5.0.23.0.G19002102412.hdf\n",
      "(135, 90)\n",
      "UTC:  2019-01-01 20:00:00\n",
      "MST:  2019-01-01 13:00:00\n",
      "CST:  2019-01-01 14:00:00\n",
      "Time of satellite data capture:  2019-01-01 13:00:00\n",
      "Error opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.192.L1B.AIRS_Rad.v5.0.23.0.G19002100753.hdf\n",
      "name 'wind_spd_dir' is not defined\n",
      "\n",
      "\n",
      "HDF file execution time: 0.42609643936157227 sec\n",
      "\n",
      "\n",
      "Opening file: D:\\NASA_AIRS\\2019\\AIRS.2019.01.01.208.L1B.AIRS_Rad.v5.0.23.0.G19002102412.hdf\n",
      "Next file:  D:\\NASA_AIRS\\2019\\AIRS.2019.01.02.089.L1B.AIRS_Rad.v5.0.23.0.G19002145359.hdf\n",
      "(135, 90)\n",
      "UTC:  2019-01-01 22:00:00\n",
      "MST:  2019-01-01 15:00:00\n",
      "CST:  2019-01-01 16:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe for the 2019 to 2021 period for radial measurements\n",
    "date_index = pd.date_range(start='2019-01-01', end='2021-12-31', freq='D')\n",
    "time_of_day = pd.date_range(start='2019-01-01', periods=24, freq='H').time\n",
    "dust_score_stats_CAMS49_mean = pd.DataFrame(index=date_index, columns=time_of_day)\n",
    "dust_score_stats_CAMS49_median = dust_score_stats_CAMS49_mean\n",
    "dust_score_stats_CAMS49_mode = dust_score_stats_CAMS49_mean\n",
    "\n",
    "\n",
    "for year in folder_year_list:\n",
    "    \n",
    "    file_path_ext=os.path.join(file_ext,year)\n",
    "    file_list=sorted(os.listdir(os.path.join(file_ext,file_path_ext)))\n",
    "    print(\"Opening folder:\", file_path_ext)\n",
    "\n",
    "    \n",
    "    file_name_cams49=f'CAMS49_{year}.xlsx'\n",
    "    file_name_cams1028=f'CAMS1028_{year}.xlsx'\n",
    "    tecq_cams49=read_xlsx_tecq(file_name_cams49)\n",
    "    tecq_cams1028=read_xlsx_tecq(file_name_cams1028)\n",
    "\n",
    "    last_ending_time_cams49=datetime(1900,1,1)\n",
    "\n",
    "    for i, file_current in enumerate(file_list):\n",
    "        if i < len(file_list) - 1:  # Ensure we don't go out of bounds\n",
    "            file_next = file_list[i + 1]\n",
    "\n",
    "        start_time=time.time()\n",
    "        file_path=os.path.join(file_path_ext,file_current)\n",
    "        file_path_next=os.path.join(file_path_ext,file_next)\n",
    "        print(\"Opening file:\", file_path)\n",
    "        print(\"Next file: \", file_path_next)\n",
    "        \n",
    "        try:\n",
    "            hdf_file = SD(file_path)\n",
    "            # Select dust_score, lat and long     \n",
    "            dust_score=hdf_file.select('dust_score')[:]\n",
    "            long=hdf_file.select('Longitude')[:]\n",
    "            lat=hdf_file.select('Latitude')[:]\n",
    "            coords=coordinates(lat,long)\n",
    "            print(dust_score.shape)\n",
    "            # Find timestamp of production\n",
    "            global_attributes = hdf_file.attributes()\n",
    "            # Get raw productiondatetime from hdf file\n",
    "            datetime_hdf_raw=find_rangedatetime(global_attributes)\n",
    "            # Convert raw string into datetime object\n",
    "            datetime_converted=datetime.strptime(datetime_hdf_raw,\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            # Round time from converted hdf datetime object to nearest hour \n",
    "            datetime_rounded_time=round_nearest_hour(datetime_converted)\n",
    "\n",
    "                \n",
    "            print(\"UTC: \",datetime_rounded_time)\n",
    "            # Convert UTC to MST (only valid for CAMS49)\n",
    "            datetime_rounded_time_mst=datetime_rounded_time-timedelta(hours=7)\n",
    "            datetime_rounded_time_cst=datetime_rounded_time-timedelta(hours=6)\n",
    "            print(\"MST: \",datetime_rounded_time_mst)\n",
    "            print(\"CST: \",datetime_rounded_time_cst)\n",
    "\n",
    "            # Convert datetime object (date part only) into string\n",
    "            datetime_converted_str_mst=datetime_rounded_time_mst.date().strftime(\"%Y-%m-%d\")\n",
    "            datetime_converted_str_cst=datetime_rounded_time_cst.date().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            '''\n",
    "            Load next hdf file to find the datetime of its data\n",
    "            '''\n",
    "            hdf_file_next = SD(file_path_next)\n",
    "            # Select dust_score, lat and long     \n",
    "            global_attributes_next = hdf_file_next.attributes()\n",
    "            # Get raw productiondatetime from hdf file\n",
    "            datetime_hdf_raw_next=find_rangedatetime(global_attributes_next)\n",
    "            # Convert raw string into datetime object\n",
    "            datetime_converted_next=datetime.strptime(datetime_hdf_raw_next,\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            # Round time from converted hdf datetime object to nearest hour \n",
    "            datetime_rounded_time_next=round_nearest_hour(datetime_converted_next)\n",
    "            next_datetime_rounded_time_mst=datetime_rounded_time_next-timedelta(hours=7)\n",
    "            hdf_file_next.end()\n",
    "            \n",
    "            perhour =1\n",
    "\n",
    "\n",
    "            \n",
    "            #for radius=0 find mean/mode/median as close as possible to cams station\n",
    "            coords_reshaped=np.reshape(coords,(coords.shape[0]*coords.shape[1],2))\n",
    "            observation_starting_time_cams49=datetime_rounded_time_mst\n",
    "            print(\"Time of satellite data capture: \", observation_starting_time_cams49)\n",
    "\n",
    "            avg_windspd_cams49=wind_spd_dir.at[datetime_rounded_time_mst.strftime('%Y-%m-%d-%H'),'Wind Speed']\n",
    "            print(\"Wind speed at start of AIRS recording: \",avg_windspd_cams49)\n",
    "\n",
    "            first_focus_last=0\n",
    "            second_focus_last=0\n",
    "            semi_major_axis_last=0\n",
    "            for elem in range(len(wind_spd_dir)):\n",
    "                #Wind speed on certain day of the year as measured at El Paso airport, only 2019 data so far!\n",
    "                \n",
    "                avg_winddir_cams49=wind_spd_dir.at[observation_starting_time_cams49.strftime('%Y-%m-%d-%H'),'Wind Direction']\n",
    "                if avg_winddir_cams49<180:\n",
    "                    avg_winddir_cams49=int((180+avg_winddir_cams49))\n",
    "                else:\n",
    "                    avg_winddir_cams49=int(np.abs(180-avg_winddir_cams49))            \n",
    "                #Draw circle every 2 hours for 12 hours, until next satellite obesrvation (which could be on the same or the next day)\n",
    "                #How much has the dust moved within the 1st two hours, look around at a circle of that radius, where the CAMS49 is a vertex on the cirle\n",
    "                if observation_starting_time_cams49>=next_datetime_rounded_time_mst:\n",
    "                    print(\"Warning: datetime overlap! \",observation_starting_time_cams49, next_datetime_rounded_time_mst)\n",
    "                    break\n",
    "                   \n",
    "                #find the other vertex based on the distance wind travels in an hour/2hours\n",
    "                distance_vertices=avg_windspd_cams49\n",
    "                distance_to_outer_vertex=avg_windspd_cams49+wind_spd_dir.at[(observation_starting_time_cams49+timedelta(hours=perhour)).strftime('%Y-%m-%d-%H'),'Wind Speed']\n",
    "                degrees_change=geopy.units.degrees(arcminutes=geopy.units.nautical(miles=distance_vertices))\n",
    "                degrees_change_next=geopy.units.degrees(arcminutes=geopy.units.nautical(miles=distance_to_outer_vertex))\n",
    "                #finding the other vertex of the same ellipse\n",
    "                lat_vertex=CAMS49[0]+degrees_change*np.sin(np.radians(avg_winddir_cams49))\n",
    "                long_vertex=CAMS49[1]+degrees_change*np.cos(np.radians(avg_winddir_cams49))\n",
    "                vertex_windv= (lat_vertex, long_vertex)\n",
    "                \n",
    "                #finding the vertex of the ellipse in the next loop\n",
    "                lat_next=CAMS49[0]+degrees_change_next*np.sin(np.radians(avg_winddir_cams49))\n",
    "                long_next=CAMS49[1]+degrees_change_next*np.cos(np.radians(avg_winddir_cams49))\n",
    "                next_vertex_windv= (lat_next, long_next)\n",
    "                \n",
    "                eccentricity=0.7\n",
    "                lat_center=CAMS49[0]+degrees_change/2*np.sin(np.radians(avg_winddir_cams49))\n",
    "                long_center=CAMS49[1]+degrees_change/2*np.cos(np.radians(avg_winddir_cams49))\n",
    "                ellipse_center=[lat_center,long_center]\n",
    "                    #dist_center=distance(CAMS49,[lat_center,long_center])\n",
    "                    #print(dist_center)\n",
    "                    #semi_major_axis is windspd_radii_cams49[elem]\n",
    "                semi_major_axis=distance_vertices/2\n",
    "                    #Currently minor axis is useless\n",
    "                semi_minor_axis= semi_major_axis*np.sqrt(1 - (eccentricity**2))\n",
    "                dist_center_to_foci=semi_major_axis*eccentricity\n",
    "                    #dist_center_to_foci=semi_major_axis**2-(semi_minor_axis)**2\n",
    "                    #print(\"DIST to CENTER\")\n",
    "                    #print(dist_center_to_foci,dist_center_to_foci2)\n",
    "                first_focus=[lat_center+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci))*np.sin(np.radians(avg_winddir_cams49)-np.pi),\n",
    "                            long_center+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci))*np.cos(np.radians(avg_winddir_cams49)-np.pi)]\n",
    "                second_focus=[lat_center+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci))*np.sin(np.radians(avg_winddir_cams49)),\n",
    "                            long_center+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci))*np.cos(np.radians(avg_winddir_cams49))]\n",
    "    \n",
    "    \n",
    "                #FIND FOCI OF NEXT ELLIPSE\n",
    "                eccentricity_next=eccentricity#+0.2\n",
    "                lat_center_next=CAMS49[0]+degrees_change_next/2*np.sin(np.radians(avg_winddir_cams49))\n",
    "                long_center_next=CAMS49[1]+degrees_change_next/2*np.cos(np.radians(avg_winddir_cams49))\n",
    "    \n",
    "\n",
    "                semi_major_axis_next=distance_to_outer_vertex/2\n",
    "                dist_center_to_foci_next=semi_major_axis*eccentricity\n",
    "    \n",
    "                    \n",
    "                first_focus_next=[lat_center_next+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci_next))*np.sin(np.radians(avg_winddir_cams49)-np.pi),\n",
    "                            long_center_next+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci_next))*np.cos(np.radians(avg_winddir_cams49)-np.pi)]\n",
    "                second_focus_next=[lat_center_next+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci_next))*np.sin(np.radians(avg_winddir_cams49)),\n",
    "                            long_center_next+geopy.units.degrees(arcminutes=geopy.units.nautical(miles=dist_center_to_foci_next))*np.cos(np.radians(avg_winddir_cams49))]                \n",
    "                \n",
    "                inside_points=points_inside_ellipse(first_focus, second_focus, semi_major_axis, coords_reshaped)    \n",
    "                if len(inside_points)!=0:\n",
    "                    if elem==0:\n",
    "                        print(\"Points found inside first ellipse, size: \", inside_points)\n",
    "                        matched_circle_coords=match_coords_circle(coords, inside_points)\n",
    "                        \n",
    "                        dust_score_mean_between_points=np.mean(dust_score[matched_circle_coords])\n",
    "                        dust_score_median_between_points=np.median(dust_score[matched_circle_coords])\n",
    "                        dust_score_mode_between_points=mode_float(dust_score[matched_circle_coords],int(len(dust_score[matched_circle_coords]))-1)[0]\n",
    "                        dust_score_stats_CAMS49_mean.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_mean_between_points\n",
    "                        dust_score_stats_CAMS49_median.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_median_between_points\n",
    "                        dust_score_stats_CAMS49_mode.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_mode_between_points\n",
    "                        '''\n",
    "                        draw_grid_plot(CAMS49, coords, inside_points, file_current, observation_starting_time_cams49.strftime('%Y-%m-%d  %H:%M:%S'), dust_score, round(distance_vertices,2), \n",
    "                                       True, round(wind_spd_dir.at[observation_starting_time_cams49.strftime('%Y-%m-%d-%H'),'Wind Speed'],2), avg_winddir_cams49, vertex_windv, semi_major_axis, semi_minor_axis)\n",
    "                        '''\n",
    "                        observation_starting_time_cams49+=timedelta(hours=perhour)\n",
    "                        avg_windspd_cams49+=wind_spd_dir.at[observation_starting_time_cams49.strftime('%Y-%m-%d-%H'),'Wind Speed']\n",
    "                        first_focus_last=first_focus\n",
    "                        second_focus_last=second_focus\n",
    "                        semi_major_axis_last=semi_major_axis\n",
    "                        continue\n",
    "                    # Points between the circles\n",
    "                    between_points=points_between_ellipses(first_focus_last, second_focus_last, first_focus_next,second_focus_next, semi_major_axis_last, semi_major_axis_next, coords_reshaped)\n",
    "                                        \n",
    "                    if len(between_points)!=0:\n",
    "                        matched_circle_coords=match_coords_circle(coords, between_points)\n",
    "                        \n",
    "                        print(\"Points found between the two ellipses, size: \", between_points.shape)\n",
    "\n",
    "                        '''\n",
    "                        draw_grid_plot(CAMS49, coords, inside_points, file_current, observation_starting_time_cams49.strftime('%Y-%m-%d  %H:%M:%S'), dust_score, round(distance_to_outer_vertex,2), \n",
    "                                   True,round(wind_spd_dir.at[observation_starting_time_cams49.strftime('%Y-%m-%d-%H'),'Wind Speed'],2), avg_winddir_cams49, vertex_windv, semi_major_axis, semi_minor_axis, between_points)\n",
    "                        '''\n",
    "                        dust_score_mean_between_points=np.mean(dust_score[matched_circle_coords])\n",
    "                        dust_score_median_between_points=np.median(dust_score[matched_circle_coords])\n",
    "                        dust_score_mode_between_points=mode_float(dust_score[matched_circle_coords],int(len(dust_score[matched_circle_coords]))-1)[0]\n",
    "                        \n",
    "                        dust_score_stats_CAMS49_mean.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_mean_between_points\n",
    "                        dust_score_stats_CAMS49_median.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_median_between_points\n",
    "                        dust_score_stats_CAMS49_mode.at[observation_starting_time_cams49.strftime('%Y-%m-%d'), observation_starting_time_cams49.time()]=dust_score_mode_between_points\n",
    "\n",
    "                        #update the last_ending_time with the latest time written into the dataframe\n",
    "                        last_ending_time_cams49=observation_starting_time_cams49\n",
    "                    \n",
    "                else:\n",
    "                    print(\"No points found inside first ellipse, drawing next circle...\")\n",
    "                    \n",
    "                observation_starting_time_cams49+=timedelta(hours=perhour)\n",
    "                avg_windspd_cams49+=wind_spd_dir.at[observation_starting_time_cams49.strftime('%Y-%m-%d-%H'),'Wind Speed']\n",
    "                first_focus_last=first_focus\n",
    "                second_focus_last=second_focus\n",
    "                semi_major_axis_last=semi_major_axis\n",
    "                print(avg_windspd_cams49)\n",
    "            print(\"Done\")\n",
    "\n",
    "            # Close the HDF4 file\n",
    "            hdf_file.end()\n",
    "        except Exception as e:\n",
    "            print(\"Error opening file:\", file_path)\n",
    "            print(e)\n",
    "            print(\"\\n\")\n",
    "        end_time=time.time()\n",
    "        runtime = end_time - start_time\n",
    "        print(f\"HDF file execution time: {runtime} sec\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        \n",
    "    \n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa29992c-e5ca-4256-a86c-96dbb28d9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dust_score_stats_CAMS49_mean.to_csv(r'C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\dust_score_stats_CAMS49ELLIPSE_mean_hourly_new.csv', encoding='utf-8')\n",
    "dust_score_stats_CAMS49_mode.to_csv(r'C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\dust_score_stats_CAMS49ELLIPSE_mode_hourly_new.csv', encoding='utf-8')\n",
    "dust_score_stats_CAMS49_median.to_csv(r'C:\\Users\\Zelda64\\Documents\\Programming\\dust_solar_power\\dust_score_stats_CAMS49ELLIPSE_median_hourly_new.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff413af-b197-4ef7-8a48-20003bcf0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_dust_pm(type: str, threshold_pm: int, threshold_dust_score: int, dust_score_pm_matches_array: list, additional_array: list = None):\n",
    "    index_year_2019=dust_score_pm_matches_array.index(['2019', '2019'])\n",
    "    index_year_2020=dust_score_pm_matches_array.index(['2020', '2020'])\n",
    "\n",
    "    dust_score_pm_matches_2019=np.array(dust_score_pm_matches_array[index_year_2019+1:index_year_2020])\n",
    "    dust_score_pm_matches_2020=np.array(dust_score_pm_matches_array[index_year_2020+1:])\n",
    "\n",
    "    if additional_array is not None:\n",
    "        \n",
    "        index_year_2019_add=additional_array.index(['2019', '2019'])\n",
    "        index_year_2020_add=additional_array.index(['2020', '2020'])\n",
    "        additional_array_2019=np.array(additional_array[index_year_2019_add+1:index_year_2020_add])\n",
    "        additional_array_2020=np.array(additional_array[index_year_2020_add+1:]) \n",
    "        dust_score_pm_matches_2019=np.concatenate((dust_score_pm_matches_2019,additional_array_2019), axis=0)\n",
    "        dust_score_pm_matches_2020=np.concatenate((dust_score_pm_matches_2020,additional_array_2020), axis=0)\n",
    "\n",
    "    mask_matches_2019=np.isnan(dust_score_pm_matches_2019).any(axis=1)\n",
    "    mask_matches_2020=np.isnan(dust_score_pm_matches_2020).any(axis=1)\n",
    "    \n",
    "    dust_score_pm_matches_2019=dust_score_pm_matches_2019[~mask_matches_2019]\n",
    "    dust_score_pm_matches_2020=dust_score_pm_matches_2020[~mask_matches_2020]\n",
    "    \n",
    "    dust_score_pm_matches_2020_filtered=dust_score_pm_matches_2020[np.logical_and(dust_score_pm_matches_2020[:,0]>threshold_pm, dust_score_pm_matches_2020[:,1]>threshold_dust_score)]\n",
    "    dust_score_pm_matches_2019_filtered=dust_score_pm_matches_2019[np.logical_and(dust_score_pm_matches_2019[:,0]>threshold_pm, dust_score_pm_matches_2019[:,1]>threshold_dust_score)]\n",
    "    print(dust_score_pm_matches_2019_filtered.shape)\n",
    "    print(dust_score_pm_matches_2020_filtered.shape)\n",
    "    \n",
    "\n",
    "    x_pm_2019=dust_score_pm_matches_2019_filtered[:,0]\n",
    "    y_dust_score_2019=dust_score_pm_matches_2019_filtered[:,1]\n",
    "    \n",
    "    x_pm_2020=dust_score_pm_matches_2020_filtered[:,0]\n",
    "    y_dust_score_2020=dust_score_pm_matches_2020_filtered[:,1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax.scatter(x_pm_2019,y_dust_score_2019, marker='.', label='2019')\n",
    "    ax.scatter(x_pm_2020,y_dust_score_2020, marker='.', label='2020')\n",
    "        \n",
    "    # Add title and show the plot\n",
    "    plt.title(f'{type} PM from CAMS49/1028 plotted with AIRS Dust_score')\n",
    "    plt.xlabel(\"PM2.5 (Âµg/m3)\")\n",
    "    plt.ylabel(\"Dust_score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    corr_coefficient_2019, p_value_2019 = pearsonr(x_pm_2019, y_dust_score_2019)\n",
    "    corr_coefficient_2020, p_value_2020 = pearsonr(x_pm_2020, y_dust_score_2020)\n",
    "    corr_coefficient_comb, p_vale_comb = pearsonr(np.concatenate((x_pm_2019,x_pm_2020)), np.concatenate((y_dust_score_2019,y_dust_score_2020)))\n",
    "    print(\"Pearson correlation coefficient 2019 data:\", corr_coefficient_2019.round(3))\n",
    "    print(\"p-value:\", p_value_2019.round(3))\n",
    "    print(\"Pearson correlation coefficient 2020 data:\", corr_coefficient_2020.round(3))\n",
    "    print(\"p-value:\", p_value_2020.round(3))\n",
    "    print(\"Pearson correlation coefficient 2019 and 2020 data:\", corr_coefficient_comb.round(3))\n",
    "    print(\"p-value:\", p_vale_comb.round(3))\n",
    "\n",
    "    plt.hist(x_pm_2019, alpha=0.5, label='PM2.5 2019')\n",
    "    plt.hist(x_pm_2020, alpha=0.5, label='PM2.5 2020')\n",
    "    plt.hist(y_dust_score_2019, alpha=0.5, label='Dust_score 2019')\n",
    "    plt.hist(y_dust_score_2020, alpha=0.5, label='Dust_score 2020')\n",
    "    \n",
    "    plt.xlabel('PM2.5 & Dust_score Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Max PM2.5 & Dust_score Data Distribution')\n",
    "    \n",
    "    plt.legend()\n",
    "        \n",
    "plot_dust_pm('Mean', 20, 0,dust_score_pm_matches_cams1028,dust_score_pm_matches_cams49)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
