{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feda09b5-c78b-4622-b027-7d007a9163f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lehri\\AppData\\Local\\Temp\\ipykernel_45552\\2959317239.py\", line 1, in <module>\n",
      "    from functions import *\n",
      "  File \"C:\\Users\\lehri\\Documents\\GitHub\\dust_solar_power\\functions.py\", line 4, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\lehri\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mode\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\dust_solar_power\\functions.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from pyhdf.SD import SD\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, time, timedelta\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dustpower\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import pearsonr\n",
    "from functions import *\n",
    "#https://www.eia.gov/electricity/data/eia923/\n",
    "file_path=r\"C:/Users/lehri/Documents/GitHub/dust_solar_power/\"\n",
    "file_generation=file_path+\"EIA923_Schedules_2_3_4_5_M_12_2019_Final_Revision.xlsx\"\n",
    "\n",
    "\n",
    "#file_ext= \"D:\\\\NASA_AIRS\"\n",
    "file_path_plots=file_path+\"Plots\"\n",
    "file_path_main=file_path+\"Generated dust_score\"\n",
    "\n",
    "dust_score_ellipse_mean_hourly=pd.read_csv(os.path.join(file_path_main,'dust_score_stats_CAMS49ELLIPSE_mean_hourly_new.csv'),index_col=0)\n",
    "dust_score_ellipse_median_hourly=pd.read_csv(os.path.join(file_path_main,'dust_score_stats_CAMS49ELLIPSE_median_hourly_new.csv'),index_col=0)\n",
    "dust_score_ellipse_mode_hourly=pd.read_csv(os.path.join(file_path_main,'dust_score_stats_CAMS49ELLIPSE_mode_hourly_new.csv'),index_col=0)\n",
    "\n",
    "\n",
    "#folder_year_list=sorted(os.listdir(file_ext))\n",
    "file_ghi_2019=file_path+\"NREL_NSRDB\\GHI_CAMS49_2019.csv\"\n",
    "file_ghi_2020=file_path+\"NREL_NSRDB\\GHI_CAMS49_2020.csv\"\n",
    "file_ghi_2021=file_path+\"NREL_NSRDB\\GHI_CAMS49_2021.csv\"\n",
    "\n",
    "generation_df=pd.read_excel(file_generation, sheet_name=\"Page 1 Generation and Fuel Data\", header=5, engine=\"openpyxl\")\n",
    "\n",
    "ghi_2019=pd.read_csv(file_ghi_2019, header=[2], engine=\"python\")\n",
    "ghi_2020=pd.read_csv(file_ghi_2020, header=[2], engine=\"python\")\n",
    "ghi_2021=pd.read_csv(file_ghi_2021, header=[2], engine=\"python\")\n",
    "ghi_df = pd.concat([ghi_2019, ghi_2020, ghi_2021], ignore_index=True)\n",
    "ghi_df_header=pd.read_csv(file_ghi_2019, engine=\"python\", nrows=1)\n",
    "ghi_df['Datetime']= pd.to_datetime(ghi_df['Year'].astype(str) + '-' + ghi_df['Month'].astype(str) + '-' + ghi_df['Day'].astype(str) + '-' + ghi_df['Hour'].astype(str), format='%Y-%m-%d-%H')\n",
    "ghi_df.set_index('Datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be858b9e-f8ee-45f4-94cf-7c5773e70fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghi_df['Cloud Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27b4b0-9771-4c14-aaac-c0aec272f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#max that solar farm can produce at a moment in time, e.g. at noon in the summer\n",
    "#assume DC (e.g. no conversion to AC, usually at efficiency of 15-20%)\n",
    "max_capacity=120000000\n",
    "dc_ac_efficiency=0.2\n",
    "Wp=400\n",
    "panel_area=2\n",
    "panel_yield=0.8\n",
    "#Performance Ratio\n",
    "PR=0.75\n",
    "number_of_panels=468384\n",
    "panel_yield\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c96109-bf2e-4112-bcc2-737a9060ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "generation_df_texas=generation_df[generation_df[\"Plant State\"]==\"TX\"]\n",
    "generation_df_texas_solar=generation_df_texas[generation_df_texas[\"Reported\\nFuel Type Code\"]==\"SUN\"]\n",
    "generation_df_texas_solar_WECC=generation_df_texas_solar[generation_df_texas[\"NERC Region\"]==\"WECC\"]\n",
    "generation_df_texas_solar_WECC[\"Plants\"]=np.arange(0,generation_df_texas_solar_WECC.shape[0],1)\n",
    "generation_df_texas_solar_WECC.set_index('Plants', inplace=True)\n",
    "#plant generation in MW near El Paso\n",
    "#Newman Solar 10MW plant\n",
    "elec_gen_2019_newman_elpaso=generation_df_texas_solar_WECC.loc[0,'Netgen\\nJanuary':'Netgen\\nDecember']\n",
    "#Montana Solar Facility 3MW plant\n",
    "elec_gen_2019_montana_elpaso=generation_df_texas_solar_WECC.loc[1,'Netgen\\nJanuary':'Netgen\\nDecember']\n",
    "#180MW power plant in texas, upton county\n",
    "elec_gen_2019_uptoncounty=generation_df_texas_solar[generation_df_texas_solar['Plant Name']==\"Upton County Solar\"]\n",
    "elec_gen_2019_uptoncounty=elec_gen_2019_uptoncounty.loc[12300]['Netgen\\nJanuary':'Netgen\\nDecember']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71741be-3026-480b-97ba-8b0697d2188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "windspd_year_mean=[]\n",
    "windspd_year_median=[]\n",
    "windspd_year_mode=[]\n",
    "for year in [2019,2020,2021]:\n",
    "    #dates_year= pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    dates_year_hours= pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='h')[:-1]\n",
    "    #print(dates_year)\n",
    "    windspd_daily_mean=[]\n",
    "    windspd_daily_median=[]\n",
    "    windspd_daily_mode=[]\n",
    "    for day in range(0,len(dates_year_hours),24):\n",
    "        one_day=ghi_df['Wind Speed'][dates_year_hours[day]:dates_year_hours[day+23]]\n",
    "        windspd_daily_mean.append(np.mean(one_day))\n",
    "        windspd_daily_median.append(np.median(one_day))\n",
    "        windspd_daily_mode.append(mode_float(one_day.values, int(len(one_day))-1)[0])\n",
    "    windspd_year_mean.append(windspd_daily_mean)\n",
    "    windspd_year_median.append(windspd_daily_median)\n",
    "    windspd_year_mode.append(windspd_daily_mode)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77820239-6041-47b7-9967-a14d16e3c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sun_hours_year=[]\n",
    "num_peak_sun_hours_year=[]\n",
    "fig,axs=plt.subplots(3, 1,figsize=(16, 6))\n",
    "count=0\n",
    "for year in [2019,2020,2021]:    \n",
    "    dates_year_hours= pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='H')[:-1]\n",
    "    dates_year= pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    dates_year_monthly=pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='M')\n",
    "    num_peak_sun_hours_hourly=[]\n",
    "    num_peak_sun_hours_daily=[]\n",
    "    num_peak_sun_hours_monthly=[]\n",
    "    \n",
    "    daily_ghi=[]\n",
    "    month_count=0\n",
    "    last_day=0\n",
    "    for day in range(0,len(dates_year_hours),24):\n",
    "        if dates_year_hours[day]==dates_year_monthly[month_count]:\n",
    "            \n",
    "            num_peak_sun_hours_monthly.append(num_peak_sun_hours_hourly[last_day:day])\n",
    "            #if len(num_peak_sun_hours_monthly)==12:\n",
    "            #    num_peak_sun_hours_year.append(num_peak_sun_hours_monthly)\n",
    "            last_day=day\n",
    "            month_count+=1\n",
    "        one_day=ghi_df['GHI'][dates_year_hours[day]:dates_year_hours[day+23]]\n",
    "        #average kWh/m^2/day\n",
    "        num_peak_sun_hours_hourly = np.append(num_peak_sun_hours_hourly,one_day/1000)\n",
    "        #num_peak_sun_hours_daily = np.append(num_peak_sun_hours_daily,sum(one_day/1000))\n",
    "        num_peak_sun_hours_daily.append(sum(one_day/1000))\n",
    "\n",
    "    num_peak_sun_hours_year.append(num_peak_sun_hours_monthly)\n",
    "    axs[count].plot(dates_year,num_peak_sun_hours_daily)\n",
    "    axs[count].set_title(f'{year} Peak Sun Hours El Paso')\n",
    "    axs[count].set_ylabel(\"Hours per Day\")    \n",
    "    #sun_hours_year = np.append(sun_hours_year,num_peak_sun_hours_daily)\n",
    "    sun_hours_year.append(num_peak_sun_hours_daily)\n",
    "    count+=1\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91bf98-2f40-45dc-a1d8-f83222dfdff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_peak_sun_hours_year_daily=np.empty((3,12))\n",
    "count=0\n",
    "for year in num_peak_sun_hours_year:\n",
    "    for month in range(len(year)):\n",
    "        num_peak_sun_hours_year_daily[count][month]=sum(year[month])\n",
    "    count+=1\n",
    "\n",
    "num_peak_sun_hours_year_daily\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a3b85-b6e9-4dcf-9b85-5ecf7eccada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#1 Peak Sun Hour is 1kWh/m^2 of solar energy\n",
    "#Calculate Energy Production from Peak Sun Hours\n",
    "energy_generation_plant_anual=[]\n",
    "energy_generation_plant=[]\n",
    "for elem in range(len([2019,2020,2021])):\n",
    "    #kWh/m2 or average peak sun hours per day per panel(panel area not required?)\n",
    "    energy_perpanel_perday=np.array(sun_hours_year[elem])*Wp/1000*panel_yield\n",
    "    #MWh of energy generation for the whole plant for a year\n",
    "    energy_generation_plant.append(energy_perpanel_perday*number_of_panels*PR/1000)\n",
    "    #Annual Solar Energy Production at farm (millions of kWh)\n",
    "    #taking into account Performance Ratio of plant\n",
    "    energy_generation_plant_anual.append(np.sum(np.array(energy_generation_plant[elem]))*1000)\n",
    "\n",
    "energy_generation_plant_anual\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdbc1b-af54-45a3-b41a-0c5cca7b8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dust_scores=[]\n",
    "dust_scores=[]\n",
    "count=0\n",
    "for year in [2019,2020,2021]:\n",
    "    fig,axs=plt.subplots(2, 1,figsize=(18, 9))\n",
    "\n",
    "    axs[0].set_title(f'Particulate Matter at CAMS49')\n",
    "    axs[0].set_ylabel(\"Concentration $\\mu {g/m}^2$\")\n",
    "    axs[1].set_title(f'Dust_score at CAMS49, with Hourly Ellipse generation (Inverted Wind)')\n",
    "    axs[1].set_ylabel(\"dust_score\")\n",
    "    #axs[2].set_title(f'Dust_score around CAMS49 Ellipse Hourly')\n",
    "    #axs[2].set_ylabel(\"dust_score\")\n",
    "\n",
    "    date_index_hourly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='H')[:-1]\n",
    "    date_index= pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    \n",
    "    file_name_cams49=file_path+f'CAMS49_{year}.xlsx'\n",
    "    file_name_cams49_pm10=file_path+f'/CAMS49_{year}_PM10.xlsx'\n",
    "    tecq_cams49=read_xlsx_tecq(file_name_cams49)\n",
    "    tecq_cams49_pm10=read_xlsx_tecq(file_name_cams49_pm10)\n",
    "    \n",
    "    \n",
    "    annual_ellipse_mean_hourly=[]\n",
    "    annual_ellipse_median_hourly=[]\n",
    "    annual_ellipse_mode_hourly=[]\n",
    "    \n",
    "\n",
    "    for day in date_index:\n",
    "        try:\n",
    "            hourly_ellipse_mean_hourly=dust_score_ellipse_mean_hourly.loc[day.date().strftime('%Y-%m-%d')].values\n",
    "            hourly_ellipse_median_hourly=dust_score_ellipse_median_hourly.loc[day.date().strftime('%Y-%m-%d')].values\n",
    "            hourly_ellipse_mode_hourly=dust_score_ellipse_mode_hourly.loc[day.date().strftime('%Y-%m-%d')].values\n",
    "                        \n",
    "            \n",
    "            #hourly_ellipse_mean_hourly=interpolate_gaps(hourly_ellipse_mean_hourly,2)\n",
    "            #hourly_ellipse_median_hourly=interpolate_gaps(hourly_ellipse_median_hourly,2)\n",
    "            #hourly_ellipse_mode_hourly=interpolate_gaps(hourly_ellipse_mode_hourly,2)\n",
    "            #hourly_dust_score_circle=interpolate_gaps(hourly_dust_score_circle,1)\n",
    "            #hourly_dust_score.fillna(method='ffill'hourly_dust_score, limit=1)\n",
    "            #print(hourly_dust_score)\n",
    "            #np.insert(annual_dust_score,[day.timetuple().tm_yday], hourly_dust_score)\n",
    "            annual_ellipse_mean_hourly.append(hourly_ellipse_mean_hourly)\n",
    "            annual_ellipse_median_hourly.append(hourly_ellipse_median_hourly)\n",
    "            annual_ellipse_mode_hourly.append(hourly_ellipse_mode_hourly)\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(\"No data found for date: \",day)\n",
    "            print(\"Stopping...\")\n",
    "            print(e)\n",
    "            break\n",
    "    \n",
    "    perday_values_annual_ellipse_mean_hourly=np.array(annual_ellipse_mean_hourly)\n",
    "    perday_values_annual_ellipse_median_hourly=np.array(annual_ellipse_median_hourly)\n",
    "    perday_values_annual_ellipse_mode_hourly=np.array(annual_ellipse_mode_hourly)\n",
    "\n",
    "    scaled_perday_values_annual_ellipse_mean_hourly = np.where(perday_values_annual_ellipse_mean_hourly < 380, perday_values_annual_ellipse_mean_hourly * 0.1, perday_values_annual_ellipse_mean_hourly)\n",
    "    scaled_perday_values_annual_ellipse_median_hourly = np.where(perday_values_annual_ellipse_median_hourly < 380, perday_values_annual_ellipse_median_hourly * 0.1, perday_values_annual_ellipse_median_hourly)\n",
    "    scaled_perday_values_annual_ellipse_mode_hourly = np.where(perday_values_annual_ellipse_mode_hourly < 380, perday_values_annual_ellipse_mode_hourly * 0.1, perday_values_annual_ellipse_mode_hourly)\n",
    "    \n",
    "    scaled_dust_scores.append(scaled_perday_values_annual_ellipse_mean_hourly)\n",
    "    dust_scores.append(perday_values_annual_ellipse_mean_hourly)\n",
    "\n",
    "    axs[0].plot(date_index_hourly, tecq_cams49.values.flatten(), label='Hourly PM2.5',color='blue',alpha=0.5)\n",
    "    axs[0].plot(date_index_hourly, tecq_cams49_pm10.values.flatten(), label='Hourly PM10',color='green',alpha=0.5)\n",
    "    \n",
    "    axs[0].legend(loc='upper right')\n",
    "    axs[1].plot(date_index_hourly, scaled_perday_values_annual_ellipse_mean_hourly.flatten(), label='Hourly Mean Peaks',color='red',alpha=0.5)\n",
    "    #axs[2].plot(date_index_hourly, perday_values_annual_ellipse_median_hourly.flatten(), label='Ellipse hr Median',color='green',alpha=0.5)\n",
    "    #axs[2].plot(date_index_hourly, perday_values_annual_ellipse_mode_hourly.flatten(), label='Ellipse hr Mode',color='blue',alpha=0.5)\n",
    "    axs[1].plot(date_index, np.nanmean(perday_values_annual_ellipse_mean_hourly,axis=1), label='Daily Mean',color='green',alpha=0.75)\n",
    "    axs[1].legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682710e2-a71a-4772-bae6-d3f83b5c9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "#kwargs = {'drawstyle' : 'steps'}\n",
    "for year in [2019,2020,2021]:\n",
    "    \n",
    "    file_name_cams49=file_path+f'CAMS49_{year}.xlsx'\n",
    "    tecq_cams49=read_xlsx_tecq(file_name_cams49)\n",
    "\n",
    "    #file_name_cams49_pm10=f'CAMS49_2019_PM10.xlsx'\n",
    "    #tecq_cams49_pm10=read_xlsx_tecq(file_name_cams49_pm10)\n",
    "    #print(tecq_cams49_pm10)\n",
    "    date_index_hourly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='H')[:-1]\n",
    "    date_index_monthly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='M')\n",
    "    print(date_index_hourly.shape)\n",
    "    date_index_daily=pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    fig,axs=plt.subplots(3, 1,figsize=(18, 9))\n",
    "    #plt.subplots_adjust(hspace=0.5)\n",
    "    axs[0].set_title(f'{year} Hourly PM2.5, GHI, and dust_score at CAMS49')\n",
    "    axs[0].set_ylabel(\"PM2.5 (μg/m3)\")\n",
    "    #axs[1].set_title(f'2019 Hourly GHI at CAMS49')\n",
    "    axs[1].set_ylabel(\"GHI (W/m2)\")\n",
    "    axs[2].set_ylabel(\"dust_score\")\n",
    "    #axs[3].set_ylabel(\"wind speed (mph)\")\n",
    "    \n",
    "    #axs[0].plot(date_index_hourly, tecq_cams49.values.flatten(), label='Hourly PM',alpha=0.5)\n",
    "    axs[0].plot(date_index_daily, np.nanmean(tecq_cams49.values,axis=1), label='Daily Mean PM2.5',color='blue',alpha=0.5)\n",
    "    #axs[0].plot(date_index_daily, np.nanmean(tecq_cams49_pm10.values,axis=1), label='Daily Mean PM10',color='green',alpha=0.5)\n",
    "\n",
    "    axs[0].legend()\n",
    "    \n",
    "    #axs[1].plot(date_index_hourly, ghi_df['DNI'], label='Hourly DNI',color='red',alpha=0.5)\n",
    "    #not that ghi['GHI'][f'{year}-01-01':f'{year}-12-31'] means that the upper limit will be {year}-12-31 00:00:00 hence the 31st will be included\n",
    "    axs[1].plot(date_index_hourly, ghi_df['GHI'][f'{year}-01-01':f'{year}-12-31'], label='Hourly GHI',color='blue',alpha=0.5)\n",
    "    \n",
    "    \n",
    "    ax2 = axs[1].twinx()\n",
    "    ax2.plot(date_index_daily, energy_generation_plant[count], label='Solar Energy Generation',color='red',alpha=0.5)\n",
    "    ax2.set_ylabel('Daily Generation (MWh)')\n",
    "    # Display legends\n",
    "    lines1, labels1 = ax2.get_legend_handles_labels()\n",
    "    lines2, labels2 = axs[1].get_legend_handles_labels()\n",
    "    axs[1].legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "        \n",
    "    axs[2].plot(date_index_hourly, scaled_dust_scores[count].flatten(), label='Hourly Mean (scaled down)',color='red',alpha=0.5)\n",
    "    axs[2].plot(date_index_daily, np.nanmean(dust_scores[count],axis=1), label='Daily Mean',color='green')\n",
    "    #axs[2].set_yscale('log')\n",
    "    axs[2].legend(loc='upper right')\n",
    "\n",
    "    #axs[3].plot(date_index_hourly, ghi_df['Wind Speed'][f'{year}-01-01':f'{year}-12-31'], label='Hourly',alpha=0.5)\n",
    "    #axs[3].plot(date_index_daily, windspd_year_mean[count], label='Daily Mean',color='green',alpha=0.75)\n",
    "    #axs[3].plot(date_index_daily, windspd_year_median[count], label='Daily Median wind speed',color='red',alpha=0.75)\n",
    "    #axs[3].plot(date_index_daily, windspd_year_mode[count], label='Daily Mode wind speed',color='blue',alpha=0.75)\n",
    "\n",
    "    #axs[3].legend(loc='upper right')\n",
    "\n",
    "    \n",
    "    #print(len(ghi_df['DNI']), len(tecq_cams49.values))\n",
    "    #corr_coefficient, p_value = pearsonr( sun_hours_year[count], np.nanmean(tecq_cams49.values[:-np.abs((len(date_index_daily)-len(sun_hours_year[count])))],axis=1))\n",
    "    corr_coefficient, p_value = pearsonr(ghi_df['GHI'][f'{year}-01-01':f'{year}-12-31'], tecq_cams49.interpolate().values.flatten())\n",
    "    corr_coefficient_wind_dust, p_value_wind_dust = pearsonr(ghi_df['Wind Speed'][f'{year}-01-01':f'{year}-12-31'], tecq_cams49.interpolate().values.flatten())\n",
    "    print(corr_coefficient, p_value )\n",
    "    print(corr_coefficient_wind_dust, p_value_wind_dust )\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a65d75-8e0a-4442-86d8-70041d8b90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation per year\n",
    "for year in [0,1,2]:\n",
    "    net_gen=sum(num_peak_sun_hours_year_daily[year]*Wp/1000*panel_yield*number_of_panels*PR)\n",
    "    print(\"Generated energy (kWh): \",net_gen)\n",
    "    print(\"Number of households: \", net_gen/south_household_consumption_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f7d88-c971-44d1-a7a3-06501d386b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for year in [2019]:\n",
    "    \n",
    "    date_index_monthly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='M')\n",
    "    fig,ax=plt.subplots(1, 1,figsize=(10, 5))\n",
    "    #plt.subplots_adjust(hspace=0.5)\n",
    "    ax.set_title(f'{year} Texas Solar Generation Comparison')\n",
    "    ax.set_ylabel(\"Monthly Generation (MWh)\")\n",
    "    \n",
    "    ax.plot(date_index_monthly, num_peak_sun_hours_year_daily[count]*Wp/1000*panel_yield*number_of_panels*PR/1000, label='Buena Vista 120MW (modeled) (MWh)',color='red',alpha=0.5)\n",
    "    ax.plot(date_index_monthly, elec_gen_2019_newman_elpaso.values, label='Newman 10MW (actual) (MWh)',color='green',alpha=0.5)\n",
    "    ax.plot(date_index_monthly, elec_gen_2019_montana_elpaso.values, label='Montana 3MW (actual) (MWh)',color='blue',alpha=0.5)\n",
    "    ax.plot(date_index_monthly, elec_gen_2019_uptoncounty.values, label='Upton County 180MW (actual) (MWh)',color='orange',alpha=0.5)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843402ee-0208-4970-972f-6dbdb47d469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for year in [2019,2020,2021]:\n",
    "    \n",
    "    file_name_cams49=f'CAMS49_{year}.xlsx'\n",
    "    tecq_cams49=read_xlsx_tecq(file_name_cams49)\n",
    "    date_index_hourly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='H')[:-1]\n",
    "    date_index_monthly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='M')\n",
    "    date_index_daily=pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    fig,axs=plt.subplots(2, 1,figsize=(18, 4))\n",
    "    #plt.subplots_adjust(hspace=0.5)\n",
    "    axs[0].set_title(f'{year} Daily PM2.5 and wind speed at CAMS49')\n",
    "    axs[0].set_ylabel(\"PM2.5 (μg/m3)\")\n",
    "    axs[1].set_ylabel('wind speed (mph)')\n",
    "    \n",
    "    axs[0].plot(date_index_daily, np.nanmean(tecq_cams49.values,axis=1), label='Daily Mean PM',color='blue',alpha=0.5)\n",
    "    axs[0].legend(loc='upper right')\n",
    "        \n",
    "    axs[1].plot(date_index_daily, windspd_year_mean[count], label='Daily Mean',color='green',alpha=0.75)   \n",
    "    \n",
    "    axs[1].legend(loc='upper right')\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1698a-f082-42d8-bca2-61d515bf7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ecdf(a):\n",
    "    x, counts = np.unique(a, return_counts=True)\n",
    "    cusum = np.cumsum(counts)\n",
    "    return x, cusum / cusum[-1]\n",
    "\n",
    "def plot_ecdf(a):\n",
    "    x, y = ecdf(a)\n",
    "    x = np.insert(x, 0, x[0])\n",
    "    y = np.insert(y, 0, 0.)\n",
    "    plt.plot(x, y, drawstyle='steps-post')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(file_path_plots,'ecdf.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833bdd7-c312-4225-a280-64e3e0b01eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_gaps(values, limit=None):\n",
    "    \"\"\"\n",
    "    Fill gaps using linear interpolation, optionally only fill gaps up to a\n",
    "    size of `limit`.\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    i = np.arange(values.size)\n",
    "    valid = np.isfinite(values)\n",
    "    filled = np.interp(i, i[valid], values[valid])\n",
    "\n",
    "    if limit is not None:\n",
    "        invalid = ~valid\n",
    "        for n in range(1, limit+1):\n",
    "            invalid[:-n] &= invalid[n:]\n",
    "        filled[invalid] = np.nan\n",
    "\n",
    "    return filled\n",
    "\n",
    "##TO DO##\n",
    "#interpolate with KNN instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff6500-cba4-44d0-94de-34049017c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, min, max):\n",
    "    \n",
    "    # Desired range\n",
    "    new_min = min\n",
    "    new_max = max\n",
    "    \n",
    "    # Calculate the minimum and maximum of the original data\n",
    "    original_min = np.min(data)\n",
    "    original_max = np.max(data)\n",
    "    #print(original_min,original_max)\n",
    "    \n",
    "    # Apply the min-max normalization formula\n",
    "    normalized_data = ((data - original_min) / (original_max - original_min)) * (new_max - new_min) + new_min\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a953fa-5338-454e-9273-ce55593e3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import energy_distance\n",
    "\n",
    "X_pms_norm=[]\n",
    "X_pms=[]\n",
    "X_dust_scores_norm=[]\n",
    "X_dust_scores=[]\n",
    "years=[2019,2020,2021]\n",
    "interpolation_limits=[10]#,10,20,40]\n",
    "\n",
    "for interpolation_limit in interpolation_limits:\n",
    "    #fig,axs=plt.subplots(3, 1,figsize=(6, 16))\n",
    "    for count in [0,1,2]:\n",
    "        file_name_cams49=f'CAMS49_{years[count]}.xlsx'\n",
    "        tecq_cams49=read_xlsx_tecq(file_name_cams49)\n",
    "        x_pm = tecq_cams49.values.flatten()\n",
    "        x_pm_int=interpolate_gaps(x_pm, limit=interpolation_limit)\n",
    "        x_pm_cleaned = x_pm_int[~np.isnan(x_pm_int)]\n",
    "        X_pms.append(x_pm_cleaned)\n",
    "        x_pm_norm=normalize(x_pm_cleaned, 0, 1)\n",
    "        F_pm = np.arange(1, len(x_pm_norm)+1/len(x_pm_norm))\n",
    "        X_pms_norm.append(x_pm_norm)\n",
    "        \n",
    "        x_dust = dust_scores[count].flatten()\n",
    "        x_dust_int=interpolate_gaps(x_dust, limit=interpolation_limit)\n",
    "        x_dust_cleaned = x_dust_int[~np.isnan(x_dust_int)]\n",
    "        X_dust_scores.append(x_dust_cleaned)\n",
    "        x_dust_norm=normalize(x_dust_cleaned, 0, 1)\n",
    "        F_dust_score = np.arange(1, len(x_dust_norm)+1/len(x_dust_norm))\n",
    "        X_dust_scores_norm.append(x_dust_norm)\n",
    "        \n",
    "        #plt.plot(np.sort(x_pm_norm), F_pm, drawstyle=\"steps-post\", label=f'PM2.5 {years[count]}', alpha=0.5)\n",
    "        #plt.plot(np.sort(x_dust_norm), F_dust_score, drawstyle=\"steps-post\", label=f'Dust_score {years[count]}', alpha=0.5)\n",
    "        #plt.legend(loc='lower right')\n",
    "        #plt.title(f'ECDF of dust_score and PM2.5 in {years[count]}')  \n",
    "        plot_ecdf(x_dust_norm)\n",
    "        plot_ecdf(x_pm_norm)\n",
    "\n",
    "        '''\n",
    "        axs[count].set_title(f'ECDF of dust_score and PM2.5 in {years[count]}, interpolation={interpolation_limit}')\n",
    "        axs[count].plot(np.sort(x_pm_norm), F_pm, drawstyle=\"steps-post\",label=f'PM2.5 {years[count]}',color='green',alpha=0.5)\n",
    "        axs[count].plot(np.sort(x_dust_norm), F_dust_score, drawstyle=\"steps-post\",label=f'Dust_score {years[count]}',color='blue',alpha=0.5)\n",
    "        axs[count].legend(loc='lower right')\n",
    "        \n",
    "        print(f'Energy Distance (dust_score, PM2.5) in {years[count]}, {interpolation_limit} = ', energy_distance(np.sort(x_pm_norm),np.sort(x_dust_norm)))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc84975-0a52-42ba-9a78-34b74b11f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation\n",
    "corr, _ = pearsonr(fortbliss_energy_mw['pvlib model'], fortbliss_energy_mw['Actual Production'])\n",
    "\n",
    "print(f\"Pearson Correlation: {corr}\")\n",
    "# Compute Euclidean distance\n",
    "dist = euclidean(fortbliss_energy_mw['pvlib model'], fortbliss_energy_mw['Actual Production'])\n",
    "\n",
    "print(f\"Euclidean Distance: {dist}\")\n",
    "dist = energy_distance(fortbliss_energy_mw['pvlib model'], fortbliss_energy_mw['Actual Production'])\n",
    "\n",
    "print(f\"Energy Distance: {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131d425-d418-4af5-8b4a-3e57162f4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_soiling_losses = pd.Series([0.98, 0.95, 0.97, 0.94, 0.93], index=pd.date_range('2023-09-01', periods=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46597965-76d0-4cf2-9727-643a29206e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "for i in [0,1,2]:\n",
    "    data=X_dust_scores[i]\n",
    "    #axs[i]=plt.hist(X_dust_scores[i])\n",
    "    # Calculate kurtosis using scipy.stats\n",
    "    # Calculate the PDF of the normal distribution\n",
    "\n",
    "    kurt = kurtosis(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data, bins=30, kde=True, color='teal', alpha=0.6)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram with KDE using Seaborn')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    print(f\"Dust_score Year {count+2019}\")\n",
    "    print(f\"Mean: {mean:.2f}\") \n",
    "    # standard deviation of the data\n",
    "    #large std means the sample has a broad spread. It is the square root of the\n",
    "    #variance, which means that it has the same units as the data.\n",
    "    print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "    # variance of the data\n",
    "    #reflects the strength of variation of the system (in this case of the PM emissions\n",
    "    #variance has the units of the data but squared, it is calculated by dividing\n",
    "    #by the denominator n-1, which is the unbiased sample variance\n",
    "    print(f\"Variance {statistics.variance(data):.2f}\")\n",
    "    # skewness of the data\n",
    "    #measures asymmetry of sample data, a 0 means a symmetric distribution about the mean\n",
    "    #skewness of a normal distribution is 0\n",
    "    #positive skewness means a long tail on the right side of the data, and vice versa\n",
    "    print(f\"Skewness {skew(data):.4f}\")\n",
    "    # kurtosis of the data\n",
    "    #degree of peakedness of a probability distrbituion\n",
    "    #positive kurtosis means high peak at the mean, neg kurtosis means low peak at the mean,\n",
    "    #thus fat and short distribution shape\n",
    "    print(f\"Kurtosis: {kurt:.4f}\")\n",
    "    # median of the data\n",
    "    print(\"The Median is %f.\" % statistics.median(data))\n",
    "    # percentiles\n",
    "    print(\"The 5th , 25th , 75th and 95th percentiles are:\")\n",
    "    probs = [5, 25, 75, 95]\n",
    "    print([round(np.percentile(data, p),5) for p in probs ])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71315ec-f28c-47c6-8178-1848443e8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "for i in [0,1,2]:\n",
    "    data=X_pms_norm[i]\n",
    "    #axs[i]=plt.hist(X_dust_scores[i])\n",
    "    # Calculate kurtosis using scipy.stats\n",
    "    # Calculate the PDF of the normal distribution\n",
    "\n",
    "    kurt = kurtosis(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(data, bins=50, kde=True, color='teal', alpha=0.6)\n",
    "    mu = 0\n",
    "    variance = 1\n",
    "    sigma = math.sqrt(variance)\n",
    "    #x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    plt.plot(x, stats.norm.pdf(x, mu, sigma), color = 'b', linewidth = 3)\n",
    "\n",
    "    plt.xlabel('PM2.5')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram with KDE using Seaborn')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    print(f\"Dust_score Year {count+2019}\")\n",
    "    print(f\"Mean: {mean:.2f}\") \n",
    "    # standard deviation of the data\n",
    "    #large std means the sample has a broad spread. It is the square root of the\n",
    "    #variance, which means that it has the same units as the data.\n",
    "    print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "    # variance of the data\n",
    "    #reflects the strength of variation of the system (in this case of the PM emissions\n",
    "    #variance has the units of the data but squared, it is calculated by dividing\n",
    "    #by the denominator n-1, which is the unbiased sample variance\n",
    "    print(f\"Variance {statistics.variance(data):.2f}\")\n",
    "    # skewness of the data\n",
    "    #measures asymmetry of sample data, a 0 means a symmetric distribution about the mean\n",
    "    #skewness of a normal distribution is 0\n",
    "    #positive skewness means a long tail on the right side of the data, and vice versa\n",
    "    print(f\"Skewness {skew(data):.4f}\")\n",
    "    # kurtosis of the data\n",
    "    #degree of peakedness of a probability distrbituion\n",
    "    #positive kurtosis means high peak at the mean, neg kurtosis means low peak at the mean,\n",
    "    #thus fat and short distribution shape\n",
    "    print(f\"Kurtosis: {kurt:.4f}\")\n",
    "    # median of the data\n",
    "    print(\"The Median is %f.\" % statistics.median(data))\n",
    "    # percentiles\n",
    "    print(\"The 5th , 25th , 75th and 95th percentiles are:\")\n",
    "    probs = [5, 25, 75, 95]\n",
    "    print([round(np.percentile(data, p),5) for p in probs ])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455a5f9-4124-4687-8cb7-dcc39cb917c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "fig,axs=plt.subplots(3, 1,figsize=(18, 9))\n",
    "for year in [2019,2020,2021]:\n",
    "    \n",
    "   \n",
    "    date_index_hourly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='H')[:-1]\n",
    "    date_index_monthly = pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='M')\n",
    "    print(date_index_hourly.shape)\n",
    "    date_index_daily=pd.date_range(start=f'{year}-01-01', end=f'{year+1}-01-01', freq='D')[:-1]\n",
    "    #plt.subplots_adjust(hspace=0.5)\n",
    "    axs[count].set_title(f'{year} dust_score at CAMS49')\n",
    "    axs[count].set_ylabel(\"dust_score\")   \n",
    "\n",
    "    #trend = np.array(np.polyfit (dust_scores[count].flatten(), date_index_hourly, 1))\n",
    "    #abline = trend[1] + x*trend[0]\n",
    "    #axs[count].plot (x, y, 'k-',color = 'tab: brown ', linewidth = 3);\n",
    "    #axs[count].plot (x, abline , 'k-', color = 'b', linewidth = 3);\n",
    "    axs[count].plot(date_index_hourly, dust_scores[count].flatten(), label='Daily Mean',color='green')\n",
    "    axs[count].legend()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff1077-3726-4a81-8ee8-36512862cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python plot Fig. 1.5: Box plot\n",
    "def generate_boxplots(data, name):\n",
    "    #data=[dust_scores[0].flatten(), dust_scores[1].flatten(), dust_scores[2].flatten()]\n",
    "    fig, ax = plt.subplots()\n",
    "    whiskerprops = dict(linestyle ='--',linewidth =2, color ='k')\n",
    "    medianprops = dict(linestyle ='-', linewidth =2, color ='k')\n",
    "    flierprops = dict(marker='o', color='orange', markersize=2, linestyle='none')\n",
    "    \n",
    "    boxplots = ax.boxplot(data, patch_artist=True, labels=['2019', '2020', '2021'],whiskerprops=whiskerprops, medianprops=medianprops, flierprops=flierprops)\n",
    "    colors=['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for patch, color in zip(boxplots['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    plt.title(f\"Boxplot of {name} at CAMS49\",pad = 20)\n",
    "    plt.ylabel(f\"{name}\",size = 15, labelpad = 20)\n",
    "    y_ticks = np.linspace(data[1].min(),data[1].max(),5)\n",
    "    plt.yticks(y_ticks)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1e0c7-0911-4470-9a3f-9ae42802ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplots(X_dust_scores, \"Dust_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463a6ff-e4a4-48f8-b776-1e0bd62fa6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplots(X_pms,\"PM2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfbb3a-c58e-498c-bf0c-cd4cb4bc93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PM2.5 data has a lot of outliers, lying beyond the 75th percentile (or 3rd quartile) + 1.5 IQR\n",
    "#Because of this we should normalize the data ... ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce349635-a6a9-42f9-8272-7e554431d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for data_row in dust_scores:\n",
    "    df=pd.DataFrame(data_row.flatten())\n",
    "    df_missing = df.isna()\n",
    "    df_num_missing = df_missing.sum()\n",
    "    print(f\"Percent of missing values NANs in {2019+count} dust_score data\")\n",
    "    print(df_num_missing / len(df))\n",
    "    print(df.isna().mean().round(4) * 100)\n",
    "    print()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b89951-5543-4bc4-a419-ad8af8825503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(pd.DataFrame(X_pms[0]))\n",
    "#[where df=data]\n",
    "plt.hist(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36c86c-af14-43c6-b8e9-ca66b32fb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_pms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4297d90-46fe-4a63-ba75-cd6d6f014924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn normalizer accepts only non nan values\n",
    "normalizer = preprocessing.Normalizer()\n",
    "norm_df = normalizer.fit_transform(pd.DataFrame(X_pms[0]))\n",
    "plt.hist(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d577c9d-6959-4f96-bbb6-5cfa328a0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "normalized_data = stats.boxcox(pd.DataFrame(X_pms[0]))\n",
    "\n",
    "# Plot both together to compare\n",
    "fig, ax=plt.subplots(1,2)\n",
    "fig.tight_layout()\n",
    "sns.distplot(modified_df['Income_of_Applicant'], ax=ax[0])\n",
    "ax[0].set_title(\"Original Data\")\n",
    "sns.distplot(normalized_data[0], ax=ax[1])\n",
    "ax[1].set_title(\"Normalized data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613d5a7-7cb9-42a6-b065-c04ee13e319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python plot Fig. 1.6: Q-Q plot for the standardized\n",
    "# global average annual mean temperature anomalies\n",
    "import statsmodels.api as sm\n",
    "x = date_index_hourly\n",
    "y = dust_scores[0].flatten()\n",
    "\n",
    "print(y.size)\n",
    "line = np.linspace (-3, 3, y.size )\n",
    "tstand = np.sort((y - np.mean (y))/ np.std(y))\n",
    "# simulate 139 points following N(0,1)\n",
    "qn = np.random.normal(size =y.size )\n",
    "qns = np.sort(qn) # sort the points\n",
    "#qq2 = sm.qqplot(qns)\n",
    "fig = plt.figure(figsize =(12,12)) # set up figure\n",
    "sm.qqplot(tstand , color = \"k\", linewidth = 1)\n",
    "sm.qqplot(qns)\n",
    "# plot diagonal line\n",
    "plt.plot(line , line , 'r-', linewidth = 1)\n",
    "# Q-Q plot of standard normal simulations\n",
    "plt.plot(line ,qns , 'mo ')\n",
    "plt.tick_params( length =6, width =2, labelsize =15)\n",
    "plt.title (\"Q-Q plot for the Standardized Global \\n Temperature Anomalies vs N(0,1)\", pad = 20)\n",
    "plt.xlabel (\" Quantile of N(0,1)\", size = 15, labelpad = 20)\n",
    "plt.ylabel (\" Quantile of Temperature Anomalies \", size = 15)\n",
    "plt.show ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
